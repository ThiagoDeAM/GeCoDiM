{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67f7618",
   "metadata": {},
   "source": [
    "# EWGCD Method: Edge-Weighted Gene Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7251b129",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3aba57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import random\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30225875",
   "metadata": {},
   "source": [
    "## Input: MAF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb2e789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 Hugo_Symbol  Entrez_Gene_Id         Center NCBI_Build  \\\n",
      "0           0     AADACL3               0  broad.mit.edu     GRCh37   \n",
      "1           1    ADAMTS19               0  broad.mit.edu     GRCh37   \n",
      "2           2       AGBL2               0  broad.mit.edu     GRCh37   \n",
      "3           3       ASCC3               0  broad.mit.edu     GRCh37   \n",
      "4           4         ATM               0  broad.mit.edu     GRCh37   \n",
      "\n",
      "  Chromosome  Start_Position  End_Position Strand       Consequence  ...  \\\n",
      "0          1        12785236      12785236      +  missense_variant  ...   \n",
      "1          5       129037220     129037220      +  missense_variant  ...   \n",
      "2         11        47726203      47726203      +  missense_variant  ...   \n",
      "3          6       101109870     101109870      +  missense_variant  ...   \n",
      "4         11       108218029     108218029      +  missense_variant  ...   \n",
      "\n",
      "  FILTER             ENSP ExAC_AF         CCDS   EXON ExAC_AF_OTH SAS_MAF  \\\n",
      "0      .  ENSP00000352268     NaN  CCDS41253.1    4/4         NaN     NaN   \n",
      "1      .  ENSP00000274487     NaN   CCDS4146.1  20/23         NaN     NaN   \n",
      "2      .  ENSP00000435582     NaN   CCDS7944.1   7/19         NaN     NaN   \n",
      "3      .  ENSP00000358159     NaN   CCDS5046.1  16/42         NaN     NaN   \n",
      "4      .  ENSP00000278616     NaN  CCDS31669.1  59/63         NaN     NaN   \n",
      "\n",
      "  Exon_Number MINIMISED PUBMED  \n",
      "0         4/4         1    NaN  \n",
      "1       20/23         1    NaN  \n",
      "2        7/19         1    NaN  \n",
      "3       16/42         1    NaN  \n",
      "4       59/63         1    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "maf_path = './inputs/prostate.maf'\n",
    "\n",
    "try:\n",
    "    maf_df = pd.read_csv(maf_path, sep='\\t', comment='#')\n",
    "    print(maf_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo MAF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f2739",
   "metadata": {},
   "source": [
    "## Mutation Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89255faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_weights = {\n",
    "    'Nonsense_Mutation': 1.0,\n",
    "    'Missense_Mutation': 0.4,\n",
    "    'Splice_Site': 0.4,\n",
    "    'Frame_Shift_Del': 1.0,\n",
    "    'Frame_Shift_Ins': 1.0,\n",
    "    'In_Frame_Del': 0.4,\n",
    "    'In_Frame_Ins': 0.4,\n",
    "    '3\\'UTR': 0.2,\n",
    "    '5\\'UTR': 0.4,\n",
    "    'Nonstop_Mutation': 0.4,\n",
    "    'Translation_Start_Site': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e0a55",
   "metadata": {},
   "source": [
    "## Output: Weighted Mutation Matrix (WMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0333b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: ./output/prostate.wmm\n"
     ]
    }
   ],
   "source": [
    "maf_df['Weight'] = maf_df['Variant_Classification'].map(mutation_weights)\n",
    "\n",
    "wmm = maf_df.groupby(['Tumor_Sample_Barcode', 'Hugo_Symbol'])['Weight'].mean().unstack(fill_value=0)\n",
    "\n",
    "output_dir = './output/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, 'prostate.wmm')\n",
    "\n",
    "wmm.to_csv(output_file, sep='\\t')\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720c9a5",
   "metadata": {},
   "source": [
    "## Output: Weighted Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c916bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: ./output/normalized_gene_scores.nwf\n"
     ]
    }
   ],
   "source": [
    "def calculate_normalized_gene_scores(maf_df, wmm):\n",
    "\n",
    "    numero_pacientes = maf_df['Tumor_Sample_Barcode'].nunique()\n",
    "    pontuacao_bruta_genes = wmm.sum(axis=0) / numero_pacientes\n",
    "    pontuacao_normalizada_genes = pontuacao_bruta_genes / pontuacao_bruta_genes.max()\n",
    "\n",
    "    pontuacoes_df = pd.DataFrame({\n",
    "        'wf': pontuacao_bruta_genes,\n",
    "        'nwf': pontuacao_normalizada_genes\n",
    "    }).reset_index()\n",
    "\n",
    "    if 'index' in pontuacoes_df.columns:\n",
    "        pontuacoes_df.rename(columns={'index': 'Gene'}, inplace=True)\n",
    "    elif 'Hugo_Symbol' in pontuacoes_df.columns:\n",
    "        pontuacoes_df.rename(columns={'Hugo_Symbol': 'Gene'}, inplace=True)\n",
    "    else:\n",
    "        print(\"Coluna não encontrada.\")\n",
    "\n",
    "    pontuacoes_df.sort_values(by='Gene', inplace=True)\n",
    "    pontuacoes_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return pontuacoes_df, pontuacoes_df['nwf']\n",
    "\n",
    "pontuacoes_df, nwf = calculate_normalized_gene_scores(maf_df, wmm)\n",
    "\n",
    "output_file = os.path.join(output_dir, 'normalized_gene_scores.nwf')\n",
    "\n",
    "pontuacoes_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e0b67",
   "metadata": {},
   "source": [
    "## Output: Consensus Network UGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a016a4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo salvo em: ./output/ugn_gene_network.ugn\n"
     ]
    }
   ],
   "source": [
    "def calculate_frequency_pairs(file_paths):\n",
    "    exact_pair_frequency = defaultdict(int)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                genes = line.strip().split()\n",
    "\n",
    "                for i in range(len(genes) - 1):\n",
    "                    pair = f\"{genes[i]} {genes[i+1]}\"\n",
    "                    exact_pair_frequency[pair] += 1\n",
    "\n",
    "    unordered_pair_frequency = defaultdict(int)\n",
    "    for pair, freq in exact_pair_frequency.items():\n",
    "        genes = pair.split()\n",
    "        unordered_pair = tuple(sorted(genes))\n",
    "        unordered_pair_frequency[unordered_pair] += freq\n",
    "\n",
    "    total_files = len(file_paths)\n",
    "    for pair in unordered_pair_frequency:\n",
    "        unordered_pair_frequency[pair] = unordered_pair_frequency[pair] / total_files\n",
    "\n",
    "    return unordered_pair_frequency\n",
    "\n",
    "def create_graph(unordered_pair_frequency):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for pair, freq in unordered_pair_frequency.items():\n",
    "        gene1, gene2 = pair\n",
    "        G.add_edge(gene1, gene2, weight=freq)\n",
    "\n",
    "    return G\n",
    "\n",
    "def save_graph_to_ugn(ugn, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for edge in ugn.edges(data=True):\n",
    "            gene1, gene2, data = edge\n",
    "            weight = data['weight']\n",
    "            file.write(f\"{gene1}\\t{gene2}\\t{weight}\\n\")\n",
    "    print(f\"Grafo salvo em: {output_file}\")\n",
    "\n",
    "file_paths = [\n",
    "    './inputs/ReactomeFI_preprocessed_122718.txt'\n",
    "]\n",
    "\n",
    "unordered_pair_frequency = calculate_frequency_pairs(file_paths)\n",
    "\n",
    "ugn = create_graph(unordered_pair_frequency)\n",
    "\n",
    "output_file = './output/ugn_gene_network.ugn'\n",
    "save_graph_to_ugn(ugn, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9247c68",
   "metadata": {},
   "source": [
    "## Output: Gene Strength Spreading Network (GSSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a182c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSSN salvo em: ./output/gssn_gene_network.gssn\n"
     ]
    }
   ],
   "source": [
    "def build_gssn(gene_network):\n",
    "    gssn = nx.DiGraph()\n",
    "    gene_network.remove_edges_from(nx.selfloop_edges(gene_network))\n",
    "    \n",
    "    max_weight = 0\n",
    "    for g_i, g_j in gene_network.edges:\n",
    "        weight_ij = gene_network[g_i][g_j][\"weight\"]\n",
    "        r_i = sum(gene_network[g_i][neighbor]['weight'] for neighbor in gene_network[g_i])\n",
    "        r_j = sum(gene_network[g_j][neighbor]['weight'] for neighbor in gene_network[g_j])\n",
    "        r_i_out = sum(gene_network[g_i][neighbor]['weight'] for neighbor in set(gene_network[g_i]) - set(gene_network[g_j]) - {g_j})\n",
    "        r_j_out = sum(gene_network[g_j][neighbor]['weight'] for neighbor in set(gene_network[g_j]) - set(gene_network[g_i]) - {g_i})\n",
    "\n",
    "        s_ij = (1 + (r_i * r_j_out)) * weight_ij\n",
    "        s_ji = (1 + (r_j * r_i_out)) * weight_ij\n",
    "\n",
    "        gssn.add_edge(g_i, g_j, weight=s_ij)\n",
    "        gssn.add_edge(g_j, g_i, weight=s_ji)\n",
    "\n",
    "        max_weight = max(max_weight, s_ij, s_ji)\n",
    "\n",
    "    for _, _, d in gssn.edges(data=True):\n",
    "        d['weight'] /= max_weight\n",
    "\n",
    "    return gssn\n",
    "\n",
    "def save_gssn_to_file(gssn, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for edge in gssn.edges(data=True):\n",
    "            gene1, gene2, data = edge\n",
    "            weight = data['weight']\n",
    "            file.write(f\"{gene1}\\t{gene2}\\t{weight:.6f}\\n\")\n",
    "    print(f\"GSSN salvo em: {output_file}\")\n",
    "\n",
    "gssn = build_gssn(ugn)\n",
    "\n",
    "output_file = './output/gssn_gene_network.gssn'\n",
    "save_gssn_to_file(gssn, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28159979",
   "metadata": {},
   "source": [
    "## Result: EWGCD Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff1ee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Result salvo em: ./output/community_results_largest_component.output\n"
     ]
    }
   ],
   "source": [
    "def calculate_clustering_coefficient(graph, community):\n",
    "    subgraph = graph.subgraph(community)\n",
    "    return nx.average_clustering(subgraph, weight='weight')\n",
    "\n",
    "def expand_cluster(graph, seed_node, visited):\n",
    "    cluster = {seed_node}\n",
    "    queue = [seed_node]\n",
    "    initial_coefficient = calculate_clustering_coefficient(graph, cluster)\n",
    "    \n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        \n",
    "        best_neighbor = None\n",
    "        best_coefficient = initial_coefficient\n",
    "        \n",
    "        for neighbor in graph.neighbors(current):\n",
    "            if neighbor not in cluster:\n",
    "                potential_cluster = cluster | {neighbor}\n",
    "                new_coefficient = calculate_clustering_coefficient(graph, potential_cluster)\n",
    "                if new_coefficient >= best_coefficient:\n",
    "                    best_coefficient = new_coefficient\n",
    "                    best_neighbor = neighbor\n",
    "        \n",
    "        if best_neighbor is not None:\n",
    "            cluster.add(best_neighbor)\n",
    "            queue.append(best_neighbor)\n",
    "            initial_coefficient = best_coefficient\n",
    "\n",
    "    visited.update(cluster)\n",
    "    return cluster\n",
    "\n",
    "def detect_communities(graph):\n",
    "    centrality = {node: val for node, val in graph.degree()}\n",
    "    sorted_nodes = sorted(centrality, key=centrality.get, reverse=True)\n",
    "    \n",
    "    communities = []\n",
    "    visited = set()\n",
    "\n",
    "    for node in sorted_nodes:\n",
    "        if node not in visited:\n",
    "            community = expand_cluster(graph, node, visited)\n",
    "            communities.append(community)\n",
    "\n",
    "    return communities\n",
    "\n",
    "def rank_communities(graph, communities):\n",
    "    ranked_communities = []\n",
    "    for community in communities:\n",
    "        coefficient = calculate_clustering_coefficient(graph, community)\n",
    "        ranked_communities.append((community, coefficient))\n",
    "    \n",
    "    ranked_communities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return ranked_communities\n",
    "\n",
    "def calculate_precision(community, known_genes):\n",
    "    known_count = len([gene for gene in community if gene in known_genes])\n",
    "    precision = known_count / len(community) if community else 0\n",
    "    return precision\n",
    "\n",
    "def save_communities_to_file(communities, known_genes, output_file):\n",
    "    data = []\n",
    "    for i, (community, score) in enumerate(communities):\n",
    "        precision = calculate_precision(community, known_genes)\n",
    "        data.append({\n",
    "            \"Comunidade\": ', '.join(sorted(community)),\n",
    "            \"Coeficiente\": f\"{score:.2f}\",\n",
    "            \"Precisão (%)\": f\"{precision:.2}\"\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.sort_values(by=[\"Coeficiente\", \"Precisão (%)\"], ascending=[False, False], inplace=True)\n",
    "    df.to_csv(output_file, sep='\\t', index=False, header=True)\n",
    "    print(f\"Community Result salvo em: {output_file}\")\n",
    "\n",
    "with open(\"./inputs/canonical_drivers.txt\", 'r') as file:\n",
    "    known_genes = set(line.strip() for line in file)\n",
    "\n",
    "largest_component = max(nx.strongly_connected_components(gssn), key=len)\n",
    "gssn_largest = gssn.subgraph(largest_component).copy()\n",
    "\n",
    "initial_communities = detect_communities(gssn_largest)\n",
    "ranked_communities = rank_communities(gssn_largest, initial_communities)\n",
    "\n",
    "output_file = \"./output/community_results_largest_component.output\"\n",
    "save_communities_to_file(ranked_communities, known_genes, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19a8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo filtrado de Comunidades salvo em: ./output/filtered_community_results.output\n"
     ]
    }
   ],
   "source": [
    "def filter_communities(input_file, output_file, threshold=0.20):\n",
    "    df = pd.read_csv(input_file, sep='\\t')\n",
    "    df['Coeficiente'] = pd.to_numeric(df['Coeficiente'], errors='coerce')\n",
    "    \n",
    "    if df['Precisão (%)'].dtype == 'object':\n",
    "        df['Precisão (%)'] = pd.to_numeric(df['Precisão (%)'].str.replace('%', ''), errors='coerce')\n",
    "    else:\n",
    "        df['Precisão (%)'] = df['Precisão (%)']\n",
    "\n",
    "    filtered_df = df[(df['Coeficiente'] > threshold) & (df['Precisão (%)'] > threshold)]\n",
    "\n",
    "    filtered_df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Arquivo filtrado de Comunidades salvo em: {output_file}\")\n",
    "\n",
    "input_file = './output/community_results_largest_component.output'\n",
    "output_file = './output/filtered_community_results.output'\n",
    "\n",
    "filter_communities(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce52c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
