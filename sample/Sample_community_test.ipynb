{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee98961f",
   "metadata": {},
   "source": [
    "# Sample of Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e317128",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e092e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import random\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e56f60",
   "metadata": {},
   "source": [
    "## Input: MAF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b692bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Hugo_Symbol  Chromosome  Start_Position  End_Position Strand  \\\n",
      "0          G1           7          100000        100000      +   \n",
      "1          G1           7          100000        100000      +   \n",
      "2          G1           7          100000        100001      +   \n",
      "3          G1           7          100000        100000      +   \n",
      "4          G1           7          100000        100000      +   \n",
      "\n",
      "   Variant_Classification Variant_Type Reference_Allele Tumor_Seq_Allele1  \\\n",
      "0       Missense_Mutation          SNP                A                 A   \n",
      "1       Nonsense_Mutation          SNP                G                 G   \n",
      "2         Frame_Shift_Ins          INS                -                 -   \n",
      "3         Frame_Shift_Del          DEL                C                 C   \n",
      "4  Translation_Start_Site          SNP                A                 A   \n",
      "\n",
      "  Tumor_Seq_Allele2 Tumor_Sample_Barcode  \n",
      "0                 T                   P3  \n",
      "1                 C                   P3  \n",
      "2                 T                   P3  \n",
      "3                 -                   P3  \n",
      "4                 T                   P3  \n"
     ]
    }
   ],
   "source": [
    "maf_path = './inputs/maf_file.maf'\n",
    "\n",
    "try:\n",
    "    maf_df = pd.read_csv(maf_path, sep='\\t', comment='#')\n",
    "    print(maf_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo MAF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbaca68",
   "metadata": {},
   "source": [
    "## Mutation Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4344b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_weights = {\n",
    "    'Nonsense_Mutation': 1.0,\n",
    "    'Missense_Mutation': 0.4,\n",
    "    'Splice_Site': 0.4,\n",
    "    'Frame_Shift_Del': 1.0,\n",
    "    'Frame_Shift_Ins': 1.0,\n",
    "    'In_Frame_Del': 0.4,\n",
    "    'In_Frame_Ins': 0.4,\n",
    "    '3\\'UTR': 0.2,\n",
    "    '5\\'UTR': 0.4,\n",
    "    'Nonstop_Mutation': 0.4,\n",
    "    'Translation_Start_Site': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a67613",
   "metadata": {},
   "source": [
    "## Output: Weighted Mutation Matrix (WMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cee00b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: ./test/test.wmm\n"
     ]
    }
   ],
   "source": [
    "maf_df['Weight'] = maf_df['Variant_Classification'].map(mutation_weights)\n",
    "\n",
    "wmm = maf_df.groupby(['Tumor_Sample_Barcode', 'Hugo_Symbol'])['Weight'].mean().unstack(fill_value=0)\n",
    "\n",
    "output_dir = './test/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, 'test.wmm')\n",
    "\n",
    "wmm.to_csv(output_file, sep='\\t')\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86ad71",
   "metadata": {},
   "source": [
    "## Output: Weighted Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3cb093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo em: ./test/normalized_gene_scores.nwf\n"
     ]
    }
   ],
   "source": [
    "def calculate_normalized_gene_scores(maf_df, wmm):\n",
    "\n",
    "    numero_pacientes = maf_df['Tumor_Sample_Barcode'].nunique()\n",
    "    pontuacao_bruta_genes = wmm.sum(axis=0) / numero_pacientes\n",
    "    pontuacao_normalizada_genes = pontuacao_bruta_genes / pontuacao_bruta_genes.max()\n",
    "\n",
    "    pontuacoes_df = pd.DataFrame({\n",
    "        'wf': pontuacao_bruta_genes,\n",
    "        'nwf': pontuacao_normalizada_genes\n",
    "    }).reset_index()\n",
    "\n",
    "    if 'index' in pontuacoes_df.columns:\n",
    "        pontuacoes_df.rename(columns={'index': 'Gene'}, inplace=True)\n",
    "    elif 'Hugo_Symbol' in pontuacoes_df.columns:\n",
    "        pontuacoes_df.rename(columns={'Hugo_Symbol': 'Gene'}, inplace=True)\n",
    "    else:\n",
    "        print(\"Coluna n達o encontrada.\")\n",
    "\n",
    "    pontuacoes_df.sort_values(by='Gene', inplace=True)\n",
    "    pontuacoes_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return pontuacoes_df, pontuacoes_df['nwf']\n",
    "\n",
    "pontuacoes_df, nwf = calculate_normalized_gene_scores(maf_df, wmm)\n",
    "\n",
    "output_file = os.path.join(output_dir, 'normalized_gene_scores.nwf')\n",
    "\n",
    "pontuacoes_df.to_csv(output_file, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Arquivo salvo em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bab685",
   "metadata": {},
   "source": [
    "## Output: Consensus Network UGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3201c298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo salvo em: ./test/ugn_gene_network.ugn\n"
     ]
    }
   ],
   "source": [
    "def calculate_frequency_pairs(file_paths):\n",
    "    exact_pair_frequency = defaultdict(int)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                genes = line.strip().split()\n",
    "\n",
    "                for i in range(len(genes) - 1):\n",
    "                    pair = f\"{genes[i]} {genes[i+1]}\"\n",
    "                    exact_pair_frequency[pair] += 1\n",
    "\n",
    "    unordered_pair_frequency = defaultdict(int)\n",
    "    for pair, freq in exact_pair_frequency.items():\n",
    "        genes = pair.split()\n",
    "        unordered_pair = tuple(sorted(genes))\n",
    "        unordered_pair_frequency[unordered_pair] += freq\n",
    "\n",
    "    total_files = len(file_paths)\n",
    "    for pair in unordered_pair_frequency:\n",
    "        unordered_pair_frequency[pair] = unordered_pair_frequency[pair] / total_files\n",
    "\n",
    "    return unordered_pair_frequency\n",
    "\n",
    "def create_graph(unordered_pair_frequency):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for pair, freq in unordered_pair_frequency.items():\n",
    "        gene1, gene2 = pair\n",
    "        G.add_edge(gene1, gene2, weight=freq)\n",
    "\n",
    "    return G\n",
    "\n",
    "def save_graph_to_ugn(ugn, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for edge in ugn.edges(data=True):\n",
    "            gene1, gene2, data = edge\n",
    "            weight = data['weight']\n",
    "            file.write(f\"{gene1}\\t{gene2}\\t{weight}\\n\")\n",
    "    print(f\"Grafo salvo em: {output_file}\")\n",
    "\n",
    "file_paths = [\n",
    "    './inputs/GeneNetwork_1_large.txt',\n",
    "    './inputs/GeneNetwork_2_large.txt',\n",
    "    './inputs/GeneNetwork_3_large.txt'\n",
    "]\n",
    "\n",
    "unordered_pair_frequency = calculate_frequency_pairs(file_paths)\n",
    "\n",
    "ugn = create_graph(unordered_pair_frequency)\n",
    "\n",
    "output_file = './test/ugn_gene_network.ugn'\n",
    "save_graph_to_ugn(ugn, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190aa48",
   "metadata": {},
   "source": [
    "## Output: Gene Strength Spreading Network (GSSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8e680b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSSN salvo em: ./test/gssn_gene_network.gssn\n"
     ]
    }
   ],
   "source": [
    "def build_gssn(gene_network):\n",
    "    gssn = nx.DiGraph()\n",
    "    gene_network.remove_edges_from(nx.selfloop_edges(gene_network))\n",
    "    \n",
    "    max_weight = 0\n",
    "    for g_i, g_j in gene_network.edges:\n",
    "        weight_ij = gene_network[g_i][g_j][\"weight\"]\n",
    "        r_i = sum(gene_network[g_i][neighbor]['weight'] for neighbor in gene_network[g_i])\n",
    "        r_j = sum(gene_network[g_j][neighbor]['weight'] for neighbor in gene_network[g_j])\n",
    "        r_i_out = sum(gene_network[g_i][neighbor]['weight'] for neighbor in set(gene_network[g_i]) - set(gene_network[g_j]) - {g_j})\n",
    "        r_j_out = sum(gene_network[g_j][neighbor]['weight'] for neighbor in set(gene_network[g_j]) - set(gene_network[g_i]) - {g_i})\n",
    "\n",
    "        s_ij = (1 + (r_i * r_j_out)) * weight_ij\n",
    "        s_ji = (1 + (r_j * r_i_out)) * weight_ij\n",
    "\n",
    "        gssn.add_edge(g_i, g_j, weight=s_ij)\n",
    "        gssn.add_edge(g_j, g_i, weight=s_ji)\n",
    "\n",
    "        max_weight = max(max_weight, s_ij, s_ji)\n",
    "\n",
    "    for _, _, d in gssn.edges(data=True):\n",
    "        d['weight'] /= max_weight\n",
    "\n",
    "    return gssn\n",
    "\n",
    "def save_gssn_to_file(gssn, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for edge in gssn.edges(data=True):\n",
    "            gene1, gene2, data = edge\n",
    "            weight = data['weight']\n",
    "            file.write(f\"{gene1}\\t{gene2}\\t{weight:.6f}\\n\")\n",
    "    print(f\"GSSN salvo em: {output_file}\")\n",
    "\n",
    "gssn = build_gssn(ugn)\n",
    "\n",
    "output_file = './test/gssn_gene_network.gssn'\n",
    "save_gssn_to_file(gssn, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fbba1",
   "metadata": {},
   "source": [
    "## Method 1 - Edge-Weighted Gene Community Detection (No Heuristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "303fe6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Result salvo em: ./test/community_results_2.output\n"
     ]
    }
   ],
   "source": [
    "def calculate_degree_centrality(graph):\n",
    "    return {node: val for node, val in graph.degree()}\n",
    "\n",
    "def calculate_clustering_coefficient(graph, community):\n",
    "    subgraph = graph.subgraph(community)\n",
    "    return nx.average_clustering(subgraph, weight='weight')\n",
    "\n",
    "def expand_cluster(graph, seed_node, visited):\n",
    "    cluster = {seed_node}\n",
    "    queue = [seed_node]\n",
    "    initial_coefficient = calculate_clustering_coefficient(graph, cluster)\n",
    "    \n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        \n",
    "        best_neighbor = None\n",
    "        best_coefficient = initial_coefficient\n",
    "        \n",
    "        for neighbor in graph.neighbors(current):\n",
    "            if neighbor not in cluster:\n",
    "                potential_cluster = cluster | {neighbor}\n",
    "                new_coefficient = calculate_clustering_coefficient(graph, potential_cluster)\n",
    "                if new_coefficient >= best_coefficient:\n",
    "                    best_coefficient = new_coefficient\n",
    "                    best_neighbor = neighbor\n",
    "        \n",
    "        if best_neighbor is not None:\n",
    "            cluster.add(best_neighbor)\n",
    "            queue.append(best_neighbor)\n",
    "            initial_coefficient = best_coefficient\n",
    "\n",
    "    visited.update(cluster)\n",
    "    return cluster\n",
    "\n",
    "def detect_communities(graph):\n",
    "    centrality = calculate_degree_centrality(graph)\n",
    "    sorted_nodes = sorted(centrality, key=centrality.get, reverse=True)\n",
    "    \n",
    "    communities = []\n",
    "    visited = set()\n",
    "\n",
    "    for node in sorted_nodes:\n",
    "        community = expand_cluster(graph, node, visited)\n",
    "        if community not in communities:\n",
    "            communities.append(community)\n",
    "\n",
    "    return communities\n",
    "\n",
    "def rank_communities(graph, communities):\n",
    "    ranked_communities = []\n",
    "\n",
    "    for community in communities:\n",
    "        coefficient = calculate_clustering_coefficient(graph, community)\n",
    "        ranked_communities.append((community, coefficient))\n",
    "    \n",
    "    ranked_communities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return ranked_communities\n",
    "\n",
    "def calculate_precision(community, known_genes):\n",
    "    known_count = len([gene for gene in community if gene in known_genes])\n",
    "    precision = known_count / len(community) if community else 0\n",
    "    return precision\n",
    "\n",
    "def save_communities_to_file(communities, known_genes, output_file):\n",
    "    data = []\n",
    "    for community, coefficient in communities:\n",
    "        precision = calculate_precision(community, known_genes)\n",
    "        data.append({\n",
    "            'Comunidade': ' '.join(sorted(community)),\n",
    "            'Coeficiente': f\"{coefficient:.2f}\",\n",
    "            'Precis達o (%)': f\"{precision:.2}\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.sort_values(by=[\"Coeficiente\", \"Precis達o (%)\"], ascending=[False, False], inplace=True)\n",
    "    df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Community Result salvo em: {output_file}\")\n",
    "\n",
    "with open(\"./inputs/canonical_drivers_test.txt\", 'r') as file:\n",
    "    known_genes = set(line.strip() for line in file)\n",
    "\n",
    "initial_communities = detect_communities(gssn)\n",
    "ranked_communities = rank_communities(gssn, initial_communities)\n",
    "\n",
    "output_file = \"./test/community_results_2.output\"\n",
    "save_communities_to_file(ranked_communities, known_genes, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334d2963",
   "metadata": {},
   "source": [
    "## Method 2 - Normalized Random Gene Clustering (No Heuristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05314ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Result salvo em: ./test/community_results_4.output\n"
     ]
    }
   ],
   "source": [
    "def calculate_clustering_coefficient(graph, community):\n",
    "    subgraph = graph.subgraph(community)\n",
    "    return nx.average_clustering(subgraph, weight='weight')\n",
    "\n",
    "def normalized_weights(weights):\n",
    "    total_weight = sum(weights)\n",
    "    return [w / total_weight for w in weights]\n",
    "\n",
    "def expand_randomly_with_weight(graph, seed_node, visited):\n",
    "    cluster = {seed_node}\n",
    "    queue = [seed_node]\n",
    "    \n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        neighbors = list(graph.neighbors(current))\n",
    "        \n",
    "        if not neighbors:\n",
    "            continue\n",
    "\n",
    "        weights = [graph[current][neighbor]['weight'] for neighbor in neighbors]\n",
    "        probabilities = normalized_weights(weights)\n",
    "        \n",
    "        for neighbor, probability in zip(neighbors, probabilities):\n",
    "            if neighbor not in cluster and random.random() < probability:\n",
    "                cluster.add(neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "    visited.update(cluster)\n",
    "    return cluster\n",
    "\n",
    "def detect_communities_random(graph):\n",
    "    nodes = list(graph.nodes())\n",
    "    random.shuffle(nodes)\n",
    "    visited = set()\n",
    "    communities = []\n",
    "\n",
    "    for node in nodes:\n",
    "        if node not in visited:\n",
    "            community = expand_randomly_with_weight(graph, node, visited)\n",
    "            communities.append(community)\n",
    "\n",
    "    return communities\n",
    "\n",
    "def calculate_driver_precision(community, canonical_drivers):\n",
    "    drivers_in_community = [gene for gene in community if gene in canonical_drivers]\n",
    "    return len(drivers_in_community) / len(community) if community else 0\n",
    "\n",
    "def rank_communities_with_precision(graph, communities, canonical_drivers):\n",
    "    ranked_communities = []\n",
    "\n",
    "    for community in communities:\n",
    "        coefficient = calculate_clustering_coefficient(graph, community)\n",
    "        precision = calculate_driver_precision(community, canonical_drivers)\n",
    " \n",
    "        ranked_communities.append((community, coefficient, precision))\n",
    "    \n",
    "    ranked_communities.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "    \n",
    "    return ranked_communities\n",
    "\n",
    "def save_communities_to_file(communities, output_file):\n",
    "    data = {\n",
    "        'Comunidade': [' '.join(sorted(comm)) for comm, _, _ in communities],\n",
    "        'Coeficiente': [f\"{coef:.2f}\" for _, coef, _ in communities],\n",
    "        'Precis達o (%)': [f\"{prec:.2}\" for _, _, prec in communities]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file, sep='\\t', index=False, header=True)\n",
    "    print(f\"Community Result salvo em: {output_file}\")\n",
    "\n",
    "canonical_drivers_path = './inputs/canonical_drivers_test.txt'\n",
    "with open(canonical_drivers_path, 'r') as f:\n",
    "    canonical_drivers = set(line.strip() for line in f)\n",
    "\n",
    "initial_communities = detect_communities_random(gssn)\n",
    "ranked_communities = rank_communities_with_precision(gssn, initial_communities, canonical_drivers)\n",
    "\n",
    "output_file = \"./test/community_results_4.output\"\n",
    "save_communities_to_file(ranked_communities, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d1e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
